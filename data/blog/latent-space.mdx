---
title: Latent embeddings  
date: '2024-06-08'
tags: ['Math', 'Machine Learning']
draft: false
summary: 'An overview of commonly used techniques associated with latent embeddings
authors: ['default']
images: ['/static/images/moco.png']
---

### Contrastive Learning

Contrastive Learning is by far the most commonly used technique to train large embedding models with transformers.

One of the first paper to explore this idea of contrastive learning for image embeddings was Momentum Encodor or MoCo([He et al. 2019](https://arxiv.org/pdf/1911.05722))

<figure>
  <img src="/static/images/moco.png" />
</figure>

### Resources

[CLIP Paper](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf)
[GTE Embedding model](https://arxiv.org/pdf/2308.03281)
[NV-Embed paper](https://arxiv.org/pdf/2405.17428)
